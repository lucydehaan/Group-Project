{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9469186-aa79-4f40-8ff7-5c3c9f186491",
   "metadata": {},
   "source": [
    "Lucy de Haan, Sean Sun, Faye Shipp, Ryan Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc90c4c-5d46-4263-8522-99136cb78521",
   "metadata": {},
   "source": [
    "___________________________________________________________________________\n",
    "Mining for Trends : An Exploratory Analysis of PLAICRAFT Data\n",
    "-----------------------------------------\n",
    "<img src='https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExdHFxdDV4ZXplZGRkeW4wbXp5ZXl0cHRiOHhrYmVvc2E0OWxhM2lxcCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ZPQLVgoXJT7K8/giphy.gif' width='450'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2852ef3-095a-4f94-8a0d-e5c04e6df414",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691c346-105f-4f82-a1d5-1789ffd22f59",
   "metadata": {},
   "source": [
    "All data has been collected from players playing Minecraft on the PLAICRAFT server. PLAICRAFT is a research project by the Pacific Laboratoy of Artificial Intelligence at UBC to collect data on habits and tendencies of Minecraft players. Minecraft is a video game set in a universe where everything is cube shaped, wherein players mine for precious stones and gems whilst attemping to build structures and survive the elements.\n",
    "\n",
    "We have been proivded with two data sets: one that tell us about a players Age, Experience, Hours played, subscription status, email, name, and gender (the players dataset), and another dataset that records logs of playtime start and stop times (the sessions dataset).\n",
    "\n",
    "In this project we aim to use the former dataset to answer the following question through data analysis, visualization, and modelling.\n",
    "\n",
    "**Question:** Given a player's age and experience, can we predict how many hours of PLAICRAFT they will play?\n",
    "\n",
    "This question is useful to the project managers in that it helps them find out which groups of people to target in their recruiting efforts in order to gather as much data as possible. To address this question, we'll apply both KNN and linear regression to the dataset and measure how they perform against each other by comparing their RMSPE values. This method is appropriate since we're trying to identify a relationship between three quantitative variables, one that is dependent (hours played) and two that are independent (experience level and age). Some assumptions required are multicollinearity, where independent variables are not highly correlated with each other, and errors in measurements between all the data points are normally distributed. Also, we assume that a relationship, either linear or non-linear, exists, as we conduct our analysis.\n",
    "\n",
    "*Note:* All visualizations in this project will feature the colour `limegreen` both because it is easily distinguishable and because it honours the creeper, an infamous character in Minecraft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03296b5-3425-4ffd-9dfc-8433d1c3bceb",
   "metadata": {},
   "source": [
    "___________________________________________________________________________\n",
    "### **Methods and Results**\n",
    "The first step is loading the tidyverse package which contains all the functions we will use to analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc86c3f-7714-4421-b7b5-cca377750d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(cowplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393890fc-4b6b-415b-9431-868ececb89be",
   "metadata": {},
   "source": [
    "The next step is reading the `players.csv` file from the web to this file so that it can be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca1787-be2e-4e83-8433-63ba521f2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_players <- \"https://raw.githubusercontent.com/lucydehaan/Group-Project/refs/heads/main/players.csv\"\n",
    "\n",
    "players_raw <- read_csv(url_players)\n",
    "\n",
    "head(players_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca2625-472b-4fde-8729-88a5b0f23a74",
   "metadata": {},
   "source": [
    "Next, we want to tidy this data so that it is easier to wrangle. We will:\n",
    "\n",
    "\n",
    "1. Convert all column names to lowercase using `tolower`and separate each word with an underscore\n",
    "2. Convert data types. ex. from `< chr >` to `< fct >`\n",
    "3. Remove `NA` values. (Since there are few `NA` values, we opt to remove them from the data set rather than replace them with the mean of their columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827e679-0d7a-4d6b-b1e0-c4cfe30d0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_tidy <- players_raw |>\n",
    "    rename_with(tolower)|>\n",
    "    mutate(gender = factor(gender)) |>\n",
    "    mutate(age = as.integer(age)) |>\n",
    "    rename(hashed_email = hashedemail) |>\n",
    "    drop_na()\n",
    "\n",
    "head(players_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bda86-6b76-442e-bd92-d4d8b394bb95",
   "metadata": {},
   "source": [
    "The next step is specifically wrangling our data for the KNN regression model we want to apply. First we convert the experience column to factors. Then we order the factors from least to most experience which establishes a relationship between the classes and allows the model to apply regression based on the scalar values assigned to these variables (1,2,3,4,5). The last step is simply selecting the columns that are pertinent to our question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785ffb7-458a-4751-b3ab-fcb76f0c4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- players_tidy |> mutate(experience = as.integer(factor(experience, \n",
    "                          levels = c(\"Beginner\", \"Amateur\", \"Regular\", \"Veteran\", \n",
    "                                     \"Pro\"), ordered = TRUE))) |>\n",
    "                        select(experience, played_hours, age)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddfbd0-c0e6-4c03-9518-a9c5a682a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data <- data |>\n",
    "  summarize(\n",
    "    min_experience = min(experience),\n",
    "    max_experience = max(experience),\n",
    "    mean_experience = mean(experience),\n",
    "    min_played_hours = min(played_hours),\n",
    "    max_played_hours = max(played_hours),\n",
    "    mean_played_hours = mean(played_hours),\n",
    "    min_age = min(age),\n",
    "    max_age = max(age),\n",
    "    mean_age = mean(age))\n",
    "\n",
    "summary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c3b2da-5a59-4d36-a625-fd0406cd621d",
   "metadata": {},
   "source": [
    "Between the two, age appears to be the most reliable solo predictor as it ranges from 8 to 50 as opposed to experience which only ranges from 1 to 5. Thus we will first test linear and knn regression using age as the sole predictor, then we will add experience as the second predictor and assess whether it improves or worsens the regression models.\n",
    "\n",
    "\n",
    "Now that we have a good idea of the ranges of the variables of interest, we can begin exploratory visualizations. First, let's visualize plot each predictor separately against the variable of interest : `played_hours`.\n",
    "\n",
    "The means of age and experience don't appear to be heavily weighted toward the maximum or minimum, however the mean of `played_hours` is heavily weighted towards the mininum. This tells us that when creating our visualizations it is likely that we will have many points near 0 hours played, so in the visualization below we will adjust our y-axis scale accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a1d17-ee1b-4382-bb10-9568bdbc75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "experience_plot <- ggplot(data,aes(x = experience, y = played_hours)) +\n",
    "    geom_point(alpha = 0.5, color = \"limegreen\") +\n",
    "    theme_minimal() +\n",
    "    labs(title = \"Figure 1: Hours Played (0 to 20) Vs. Experience\",\n",
    "         x = \"Experience Level\",\n",
    "         y = \"Hours Played\") +\n",
    "    scale_y_continuous(limits = c(NA, 30)) + #only show hours played from 0 to 30\n",
    "    theme(panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n",
    "          text = element_text(size = 16))\n",
    "\n",
    "age_plot <- ggplot(data,aes(x = age, y = played_hours)) +\n",
    "    geom_point(alpha = 0.5, color = \"limegreen\") +\n",
    "    theme_minimal() +\n",
    "    labs(title = \"Figure 2: Hours Played (0 to 20) Vs. Age\",\n",
    "         x = \"Age in Years\",\n",
    "         y = \"Hours Played\") +\n",
    "    scale_y_continuous(limits = c(NA, 30)) + #only show hours played from 0 to 30\n",
    "    theme(panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n",
    "          text = element_text(size = 16))\n",
    "\n",
    "plot_grid(experience_plot, age_plot, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68679132-0303-42ae-b4c0-52a041328fb0",
   "metadata": {},
   "source": [
    "### KNN Regression\n",
    "Since there does not appear to be a strong linear relationship in either of the predictors, we will start with KNN regression as opposed to linear regression. Here we split the tidy data and apply a KNN regression model to the training set. We chose to split it into 25% testing and 75% training because we have a relatively small data set with under 200 observations. We wanted to ensure we could maintain a sizeable testing set to adequately analyze the efficacy of our model at the end. Even though the data set is small, there are enough observations to use a 10-fold cross validation which could result in a more fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4e6b3-2757-4ecc-8f12-6b5006b1151f",
   "metadata": {},
   "outputs": [],
   "source": [
    " set.seed(69420)\n",
    "\n",
    "data_split <- initial_split(data, prop = 0.75, strata = played_hours)  \n",
    "data_train <- training(data_split)\n",
    "data_test <- testing(data_split)\n",
    "\n",
    "age_recipe <- data_train_recipe <- recipe(played_hours ~ age, data = data_train) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "age_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |> \n",
    "      set_engine(\"kknn\") |>\n",
    "      set_mode(\"regression\") \n",
    "\n",
    "age_vfold <- vfold_cv(data_train, v = 10, strata = played_hours)\n",
    "\n",
    "age_workflow <- workflow() |>\n",
    "    add_recipe(age_recipe) |>\n",
    "    add_model(age_spec)\n",
    "\n",
    "gridvals <- tibble(neighbors = seq(from = 5, to = 80, by = 5))\n",
    "\n",
    "age_results <- age_workflow |>\n",
    "  tune_grid(resamples = age_vfold, grid = gridvals) |>  \n",
    "    collect_metrics()\n",
    "\n",
    "age_k_min <- age_results |>\n",
    "    filter(.metric == \"rmse\") |>\n",
    "    slice_min(mean, n=1)\n",
    "\n",
    "age_k_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15edb02a-970f-43eb-8a1a-3f0556d47d44",
   "metadata": {},
   "source": [
    "This tells us that the k value with the lowest root mean squared error (RMSE) is k = 30, which we can now apply to the test data (`data_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00560493-ad5c-4fdd-a00e-a2ad4464d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_min <- age_k_min |>\n",
    "         pull(neighbors)\n",
    "\n",
    "age_best_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = age_min) |>\n",
    "         set_engine(\"kknn\") |>\n",
    "         set_mode(\"regression\")\n",
    "\n",
    "age_best_fit <- workflow() |>\n",
    "         add_recipe(age_recipe) |>\n",
    "         add_model(age_best_spec) |>\n",
    "         fit(data = data_train)\n",
    "\n",
    "#evaluate the model\n",
    "data_summary <- age_best_fit |>\n",
    "          predict(data_test) |>\n",
    "          bind_cols(data_test) |>\n",
    "          metrics(truth = played_hours, estimate = .pred)\n",
    "data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f727f3-bf0d-40f5-bcb9-122dded01a06",
   "metadata": {},
   "source": [
    "Now that we have collected summary statistics for our model before and after testing it on `data_test`, we can visualize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a04042-3efa-4047-b394-84d9c7032125",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "age_preds <- age_best_fit |>\n",
    "    predict(data_train)|>\n",
    "    bind_cols(data_train)\n",
    "\n",
    "marathon_plot <- age_preds |>\n",
    "    ggplot(aes(x = age, y = played_hours)) +\n",
    "    geom_point(alpha = 0.5) +\n",
    "    theme_minimal() +\n",
    "    geom_line(data = arrange(age_preds, age),\n",
    "        mapping = aes(x = age, y = .pred),\n",
    "        color = \"limegreen\",\n",
    "        linewidth = 1) +\n",
    "    labs(x = \"Age in Years\",\n",
    "         y= \"Hours Played\",\n",
    "         title = \"Figure 3: Hours Played (full range) Vs. Age\") +\n",
    "    theme(panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n",
    "          text = element_text(size = 16))\n",
    "\n",
    "marathon_log_plot <- age_preds |>\n",
    "    ggplot(aes(x = age, y = played_hours)) +\n",
    "    geom_point(alpha = 0.5) +\n",
    "    theme_minimal() +\n",
    "    scale_y_continuous(limits = c(NA, 20)) +\n",
    "    geom_line(data = arrange(age_preds, age),\n",
    "        mapping = aes(x = age, y = .pred),\n",
    "        color = \"limegreen\",\n",
    "        linewidth = 1) +\n",
    "    labs(x = \"Age in Years\",\n",
    "         y= \"Hours Played\",\n",
    "         title = \"Figure 4: Hours Played (0 to 20) Vs. Age\") +\n",
    "    theme(panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n",
    "          text = element_text(size = 16))\n",
    "\n",
    "plot_grid(marathon_plot, marathon_log_plot, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80ece3-323d-4078-871a-6c214c8625ab",
   "metadata": {},
   "source": [
    "Since most of the data is concentrated near the x axis (at 0 hours played), we opted to add a plot that only shows 0 to 20 hours played to get a clearer picture of the model. 0 to 20 was chosen because it is a range that is inclusive of the trendline and the points around it while not leaving too much negative space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5536a1-f54f-490f-99e8-c6ad9b5ebf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(69420)\n",
    "\n",
    "data_train_recipe <- recipe(played_hours ~ experience + age , data = data_train) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "#find optimal k\n",
    "data_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |> \n",
    "      set_engine(\"kknn\") |>\n",
    "      set_mode(\"regression\") \n",
    "\n",
    "data_vfold <- vfold_cv(data_train, v = 10, strata = played_hours)\n",
    "\n",
    "data_workflow <- workflow() |>\n",
    "    add_recipe(data_train_recipe) |>\n",
    "    add_model(data_spec)\n",
    "\n",
    "gridvals <- tibble(neighbors = seq(from = 5, to = 80, by = 5))\n",
    "\n",
    "k_data_results <- data_workflow |>\n",
    "  tune_grid(resamples = data_vfold, grid = gridvals) |>  \n",
    "    collect_metrics()\n",
    "\n",
    "k_data_min <- k_data_results |>\n",
    "    filter(.metric == \"rmse\") |>\n",
    "    slice_min(mean, n=1)\n",
    "\n",
    "k_data_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772a2cd-6375-4282-9cc5-4ec736142808",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(69420)\n",
    "\n",
    "k_min <- k_data_min |>\n",
    "         pull(neighbors)\n",
    "\n",
    "data_best_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = k_min) |>\n",
    "         set_engine(\"kknn\") |>\n",
    "         set_mode(\"regression\")\n",
    "\n",
    "data_best_fit <- workflow() |>\n",
    "         add_recipe(data_train_recipe) |>\n",
    "         add_model(data_best_spec) |>\n",
    "         fit(data = data_train)\n",
    "\n",
    "#evaluate the model\n",
    "data_summary <- data_best_fit |>\n",
    "          predict(data_test) |>\n",
    "          bind_cols(data_test) |>\n",
    "          metrics(truth = played_hours, estimate = .pred)\n",
    "\n",
    "data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385f7a4-c0c8-4bfd-80e1-5ebb12c67912",
   "metadata": {},
   "source": [
    "We cannot produce a visualization for multi-predictor KNN regression because it would have to be 3D and 3D models are avoided in DSCI 100. However this model still produces useful statistics to be evaluated in the discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c4762-0e49-4f9c-95cd-db40629b4988",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65320c93-f0b2-4f14-a0c3-17fb134612bf",
   "metadata": {},
   "source": [
    "Now, using the initial split of the dataset we used for the KNN-Regression model, we'll construct our linear regression model and compare errors between the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c0990-c243-4d56-9c41-c864c4e009e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_spec <- linear_reg() |>\n",
    "  set_engine(\"lm\") |>\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "lm_recipe <- recipe(played_hours ~ age, data = data_train)\n",
    "\n",
    "lm_fit <- workflow() |>\n",
    "  add_recipe(lm_recipe) |>\n",
    "  add_model(lm_spec) |>\n",
    "  fit(data = data_train)\n",
    "\n",
    "lm_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf8036-61c1-4d66-ab8f-ab67b6790f33",
   "metadata": {},
   "source": [
    "From our fitted model, we obtain our intercept and slope. The equation for the straight line is then given by "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc6e1e-bb5c-4a0a-b621-4abf0a98cc4e",
   "metadata": {},
   "source": [
    "$$ \\text{hours played} = 11.1985  -(0.2529 \\cdot \\text{age}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e2d54-40f2-4a5d-828b-65dfc3f42f07",
   "metadata": {},
   "source": [
    "This interpretation for this equation is that the model predicts that hours played start at 11.1985 at age zero, and that every one year increase in age nets a 0.2529 hour decrease in hours played. Note that this reasoning is given under the contraints of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7a290-595d-4fbc-a68d-2b4dd09a3af4",
   "metadata": {},
   "source": [
    "Next, we'll calculate the RMSPE and compare it to one produced for our knn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454befe-9afb-4dd2-8c3a-403aad3f13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_test_results <- lm_fit |>\n",
    "  predict(data_test) |>\n",
    "  bind_cols(data_test) |>\n",
    "  metrics(truth = played_hours, estimate = .pred)\n",
    "\n",
    "lm_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80954310-5368-480a-95ae-e8e492aa0fc7",
   "metadata": {},
   "source": [
    "Finally, we'll visualize our linear regression model by calculating the minimum and maximum values of our set and connecting it with a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e47b60-f53b-44d3-9229-96f33d75209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "hours_prediction_grid <- tibble(\n",
    "    age = c(\n",
    "        data |> select(age) |> min(),\n",
    "        data |> select(age) |> max()\n",
    "    )\n",
    ")\n",
    "\n",
    "hours_pred <- lm_fit |>\n",
    "  predict(hours_prediction_grid) |>\n",
    "  bind_cols(hours_prediction_grid)\n",
    "\n",
    "linear_plot <- ggplot(data, aes(x = age, y = played_hours)) +\n",
    "  geom_point(alpha = 0.4) +\n",
    "  geom_line(data = hours_pred,\n",
    "            mapping = aes(x = age, y = .pred),\n",
    "            color = \"limegreen\",\n",
    "            linewidth = 1) +\n",
    "  theme_minimal() + \n",
    "  labs(x = \"Age in Years\",\n",
    "        y = \"Total played time (hours)\",\n",
    "        title = \"Figure 5: Hours played Vs. Age (linear)\") +\n",
    "  theme(panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n",
    "        text = element_text(size = 16))\n",
    "\n",
    "\n",
    "linear_plot_range <- ggplot(data, aes(x = age, y = played_hours)) +\n",
    "  geom_point(alpha = 0.4) +\n",
    "  geom_line(data = hours_pred,\n",
    "            mapping = aes(x = age, y = .pred),\n",
    "            color = \"limegreen\",\n",
    "            linewidth = 1) +\n",
    "  theme_minimal() + \n",
    "  xlab(\"Age in Years\") +\n",
    "  ylab(\"Total played time (hours)\") +\n",
    "  ggtitle(\"Figure 6: Hours played (0 to 20) Vs. Age (linear)\") +\n",
    "  scale_y_continuous(limits = c(NA, 20)) +\n",
    "  theme(panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n",
    "          text = element_text(size = 16))\n",
    "\n",
    "plot_grid(linear_plot, linear_plot_range, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc98aaa-3990-47ac-8b99-2562221b2a93",
   "metadata": {},
   "source": [
    "Again, a plot with a smaller range of hours played (0 to 20) was added for comparison and ease of visualization of the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651839b-77df-4997-a170-8eaa4274499b",
   "metadata": {},
   "source": [
    "Next we will add `experience` as a predictor and collect statistics on the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f010a-cd1a-440f-acbc-30dd52b3931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_spec <- linear_reg() |>\n",
    "  set_engine(\"lm\") |>\n",
    "  set_mode(\"regression\")\n",
    "\n",
    "lm_recipe2 <- recipe(played_hours ~ age + experience, data = data_train)\n",
    "\n",
    "lm_fit2 <- workflow() |>\n",
    "  add_recipe(lm_recipe2) |>\n",
    "  add_model(lm_spec) |>\n",
    "  fit(data = data_train)\n",
    "\n",
    "lm_fit2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c52e7-b2fd-4a10-8081-9ddd23a9b307",
   "metadata": {},
   "source": [
    "From our fitted model, we obtain our intercept and slope. The equation for the straight line is similar to the single predictor equation, with one more term added for experience:    \n",
    "$$ \\text{hours played} = 10.1370 -(0.2474 \\cdot \\text{age}) +(0.3590 \\cdot \\text{experience})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a725d7c-10d4-408b-a8e4-1c4d2e898538",
   "metadata": {},
   "source": [
    "This model is still linear but with the two vectors of age and experience, it will be a 3D plane instead of a 2D line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a70567-f528-4655-8170-424aecb47926",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_test_results2 <- lm_fit2 |>\n",
    "  predict(data_test) |>\n",
    "  bind_cols(data_test) |>\n",
    "  metrics(truth = played_hours, estimate = .pred)\n",
    "\n",
    "lm_test_results2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db9cb3-ec32-46f8-8dec-777f65debe0a",
   "metadata": {},
   "source": [
    "Similarly to multivariable KNN regression, we cannot visualize this model without producing a 3D model. However the statistics will be useful for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d67da7-6ea2-4fac-99df-0306aaf36de2",
   "metadata": {},
   "source": [
    "___________________________________________________________________________\n",
    "### **Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59686d-3a29-45ac-8d64-2c800bb6b623",
   "metadata": {},
   "source": [
    "**Comparison Between Simple and Multivariable Regression Models**\n",
    "\n",
    "In terms of KNN regression, age as the single predictor returned an RMSPE value of 23.91 whereas when experience was added to the recipe, the RMSPE lowered to 23.20. \n",
    "\n",
    "As for linear regression, age as the sole predictor gave an RMSE of 22.59 whereas when experience was added to the recipe, the RMSE increased slightly to 22.63.\n",
    "\n",
    "Overall the negligible difference (less than 1) between using simple regression and multivariable regression indicates that both predictors are equally poor at predicting hours played. If experience level was a more accurate predictor than age, we would have seen a significant decrease in RMSPE. Inversely, if experience level was a worse predictor in age, we would have seen an increase in RMSPE.\n",
    "\n",
    "Considering the scale of hours played ranged from 0 to 223.1, all RMSPE's are very large proportionally to the range, indicating a poor model. This was partly expected going into the project since we started with fewer than 200 observations and the observations were unevenly distributed: largely centered around 0 hours played with a mean of 5.9 or 5 hours and 54 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffbf2f6-3a11-42a6-b1ef-d0eb8c68b093",
   "metadata": {},
   "source": [
    "**Comparison between our Linear Regressison and KNN Regression Models Overall**    \n",
    "The best calculated RMSPE values between our KNN and linear regression models are 23.20 and 22.59 respectively. Given RMSPE as our metric, our linear regression model has better performance in this particular case. However, given the constraints of our dataset, we cannot confidently judge which model is better for modeling the relationship in this case. For example, the linear model performing better contradicts our initial analysis of the data that there were no strong linear relationships. Linear regression is only supposed to be better fitted than KNN regression when there is an observable linear relationship between variables (Timbers et al., 2024).\n",
    "\n",
    "Currently, both models are limited by the lack of variety of data relevant to the analysis, which may create large random error in the model. As for the method itself, in the event that the relationship is non-linear, the model may not capture such a relation in a sufficiently accurate manner. It appears that most of the highest time played occurs in roughly the ages 15-27 range. Also, majority of points seem be concentrated at around zero hours played. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74973bc1-5044-4289-9fe4-009ff3b16d97",
   "metadata": {},
   "source": [
    "**Impact and Future Discussions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed395ff-e5c4-4c13-a936-474e658be4aa",
   "metadata": {},
   "source": [
    "Overall, it would be interesting to perform another analysis in a few months when the study has collected more data. We found the small data set was not conducive to regression models but was fairly responsive to simpler analyses such as basic visualizations performed at the beginning of the project and the many visualizations produced in the Individual Project Planning Stage.\n",
    "\n",
    "One of the tricky parts of the project was deciding whether or not to exclude outliers, for example the participant who contributed 223.1 hours of playing time. However in the end we decided to keep as many data points as we could (`NA` values excluded), because we were working with an already small data set. Additionally, since the the players of interest to the PLAICRAFT research group are those who contribute many hours, it seemed counterintuitive to eliminate them from our analysis.\n",
    "\n",
    "These findings hinted at possible relationships between age and hours played. The KNN regression model showed that ages between 15-25 were likely to contribute the most data. The linear regression model (limited by it's linearity) showed that younger ages tended to contribute more data. The conclusion from the KNN model is more useful to the PLAICRAFT project as it provides a specific demographic for the researchers to target. The linear conclusion implies that babies are likely to contribute the most amount of data, which is nonsensical. The KNN model being more rational than the linear model indicates that lower RMSPE is not always the definite indicator of the best model. There are instances where human discernment comes into play. For example, knowing that babies do not play video games, and that users may not always input correct registration information (how would a baby register for PLAICRAFT anyways?).\n",
    "\n",
    "Some future questions we have are:\n",
    "\n",
    "- Could we evaluate consistency/reccurence as well as total time played? For instance, a regular contributor could be more valuable than a contributor who plays one long session and never comes back.\n",
    "- Is gender a factor in hours played? If females contribute more on average, but males are easier to recruit, is it statistically beneficial to put more effort into recruiting men or women?\n",
    "- Experience level is quite a vague metric. Is there another metric that could be more accurate such as years of Minecraft played or could players be classed based on a Minecraft quiz?\n",
    "- How else could we class players?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1acf01-0b55-4075-aa38-39c815ef77c8",
   "metadata": {},
   "source": [
    "___________________________________________________________________________\n",
    "### **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c86293-e983-4b87-b846-4c8dd10cd014",
   "metadata": {},
   "source": [
    "Introductory GIF: https://giphy.com/gifs/zombie-pit-ensues-ZPQLVgoXJT7K8\n",
    "\n",
    "Textbook: Timbers, T., Campbell, T., & Lee, M. (2024). Data Science: A First Introduction. In    datasciencebook.ca. CRC Press. https://datasciencebook.ca/\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
